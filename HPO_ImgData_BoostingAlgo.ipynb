{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ImgData_BoostingAlgo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY7rMtaApkcm",
        "colab_type": "text"
      },
      "source": [
        "# **Performance of Gradient Boosting Algorithms on a Image Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15kpfM_tpoSQ",
        "colab_type": "text"
      },
      "source": [
        "# This Notebook contains the comparative analysis of 3 Boosting Algorithms -\n",
        "XGBoost, CatBoost and LightGBM trained and tested on a Image Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-paFoG9muPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install xgboost --quiet\n",
        "!pip install catboost --quiet\n",
        "!pip install lightgbm --quiet\n",
        "!pip install hyperopt --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0MYZzRwkvX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from sklearn import metrics\n",
        "import catboost as ctb\n",
        "from sklearn.model_selection import cross_val_score    \n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import sys\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score \n",
        "import lightgbm as lgb\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from catboost import Pool,CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lETAqMFrk8Jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data: shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhkXraBPp2Z-",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocess the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLD3Cekkk_rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # X_train is 50000 rows of 3x32x32 values --> reshaped in 50000 x 3072\n",
        "RESHAPED = 3072\n",
        "\n",
        "X_train = X_train.reshape(50000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gUMoIO_lG-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # normalize the datasets\n",
        "X_train /= 255.\n",
        "X_test /= 255.\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY0gdLv0qg-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "def multiclass_roc_auc_score(y_test, pred, average=\"macro\"):\n",
        "    lb = preprocessing.LabelBinarizer() \n",
        "    lb.fit(y_test)\n",
        "    y_test = lb.transform(y_test)\n",
        "    pred = lb.transform(pred)\n",
        "    return roc_auc_score(y_test, pred, average=average)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BiF0Umdp9q0",
        "colab_type": "text"
      },
      "source": [
        "# **Fit CatBoost model to the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gur4wMptoo9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_hps = {  \n",
        "            'learning_rate':      hp.loguniform('learning_rate', -5.0, -2.3),\n",
        "            'depth':              hp.choice('depth',np.arange(5,16,1,dtype = int)),\n",
        "            'l2_leaf_reg':       hp.quniform('l2_leaf_reg',2, 16, 1),\n",
        "            'random_seed':       hp.choice('random_seed',np.arange(5, 10, 1,dtype=int)),\n",
        "            'colsample_bylevel': hp.quniform('colsample_bylevel',0.3, 0.8, 0.1),\n",
        "            'n_estimators':      hp.choice('n_estimators',np.arange(100,160,10,dtype = int))\n",
        "        }\n",
        "\n",
        "depth_list = [i for i in range(5,16,1)]\n",
        "est_list = [i for i in range(100,160,10)]\n",
        "## Manual Best till date Checkpoint ##\n",
        "# params = {'num_leaves':150, 'objective':'binary','max_depth':7,'learning_rate':.05,'max_bin':200}\n",
        "# params['metric'] = ['auc', 'binary_logloss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu46iCSHp28Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_list_cb = []\n",
        "#cat_features = np.where(X_train.dtypes!=float)[0]\n",
        "def HPO_cb(cb_hps):\n",
        "    num_round = 50\n",
        "    model = CatBoostClassifier(**cb_hps,silent = True)\n",
        "    model.fit(X_train,y_train)\n",
        "    pred = model.predict_proba(X_test)[:,1]\n",
        "    accuracy_cb = multiclass_roc_auc_score(y_test,pred).mean()\n",
        "    accuracy_list_cb.append(accuracy_cb)\n",
        "    return {'loss': -accuracy_cb, 'status': STATUS_OK }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIm_xktFp_c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trials = Trials()\n",
        "best_cb = fmin(fn= HPO_cb,\n",
        "            space= cb_hps,\n",
        "            algo= tpe.suggest,\n",
        "            max_evals = 1,\n",
        "            trials = trials\n",
        "            )\n",
        "max_acc_cb = max(accuracy_list_cb)\n",
        "print(\"Best Hyperparameters for CatBoost are: \\n\")\n",
        "best_cb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTDx5PXXqFaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = ['n_estimators','random_seed','learning_rate','depth','l2_leaf_reg','colsample_bylevel']\n",
        "f, axes = plt.subplots(nrows=3, ncols=2, figsize=(15,8))\n",
        "f.tight_layout()\n",
        "cmap = plt.cm.jet\n",
        "for i, val in enumerate(parameters):\n",
        "    if val == 'depth':\n",
        "      best_cb[val] = depth_list[best_cb[val]]\n",
        "    elif val == 'n_estimators':\n",
        "      best_cb[val] = est_list[best_cb['n_estimators']]\n",
        "    elif val == 'random_seed':\n",
        "      best_cb[val]+=5\n",
        "    print(\"Best \" + str(val) + \"   =   \" + str(best_cb[val]))\n",
        "    xs = np.array([t['misc']['vals'][val] for t in trials.trials]).ravel()\n",
        "    ys = [-t['result']['loss'] for t in trials.trials]\n",
        "    xs, ys = zip(*sorted(zip(xs, ys)))\n",
        "    ys = np.array(ys)\n",
        "    c=np.array(cmap(float(i)/len(parameters)))\n",
        "    axes[i//2,i%2].scatter(xs, ys, s=20, linewidth=0.01, alpha=0.5, c=c.reshape(1,-1))\n",
        "    axes[i//2,i%2].scatter(best_cb[val],max_acc_cb,color = \"red\")\n",
        "    axes[i//2,i%2].set_title(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYCfKz_7lKoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_features = np.where(X_train.dtypes!=float)[0]\n",
        "model = CatBoostClassifier(      \n",
        "                                  n_estimators = best_cb['n_estimators'],\n",
        "                                  colsample_bylevel = best_cb['colsample_bylevel'],\n",
        "                                  learning_rate = best_cb['learning_rate'],\n",
        "                                  l2_leaf_reg = best_cb['l2_leaf_reg'], \n",
        "                                  random_seed = best_cb['random_seed'],\n",
        "                                  depth = best_cb['depth'],\n",
        "                                  silent = True\n",
        "                           )\n",
        "t1=datetime.now()\n",
        "model.fit(X_train,y_train,cat_features=cat_features)\n",
        "t2=datetime.now()\n",
        "execution_time_cat_boost = t2-t1\n",
        "t3 = datetime.now()\n",
        "pred = model.predict(X_test)\n",
        "#pred = model.predict_proba(X_test)[:,1]\n",
        "t4 = datetime.now()\n",
        "accuracy_cat_boost= round(multiclass_roc_auc_score(y_test, pred, average=\"macro\"),5)\n",
        "#accuracy_cat_boost = round(roc_auc_score(y_test,pred,multi_class=\"ovr\",average=None),5)\n",
        "#roc_auc_score(y_score=np_pred, y_true=np_label, multi_class=\"ovr\",average=None)\n",
        "print(\"Accuracy score = \",accuracy_cat_boost*100,\"%\")\n",
        "print(\"Execution time = \",execution_time_cat_boost)\n",
        "print(\"Prediction time = \",t4-t3)\n",
        "cat_boost_train_time = t2-t1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVoERUHwqJaN",
        "colab_type": "text"
      },
      "source": [
        "# **Fit LightGBM model to the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amgcu7snn4tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgb_hps = { 'num_leaves': hp.choice('num_leaves',np.arange(100, 200, 10, dtype=int)),\n",
        "            'max_depth': hp.choice('max_depth',np.arange(5, 16, 1, dtype=int)),\n",
        "            'n_estimators': hp.quniform('n_estimators', 10, 700, 1),\n",
        "            'feature_fraction': hp.uniform('feature_fraction', 0.75, 1.0),\n",
        "            'bagging_fraction': hp.uniform('bagging_fraction', 0.75, 1.0),\n",
        "            'learning_rate': hp.loguniform('learning_rate', -5.0, -2.3),\n",
        "            'lambda_l1': hp.uniform('lambda_l1', 0, 10),\n",
        "            'lambda_l2': hp.uniform('lambda_l2', 0, 10)\n",
        "          }\n",
        "\n",
        "num_leaves_list = [100,110,120,130,140,150,160,170,180,190,200]\n",
        "## Manual Best till date Checkpoint ##\n",
        "# params = {'num_leaves':150, 'objective':'binary','max_depth':7,'learning_rate':.05,'max_bin':200}\n",
        "# params['metric'] = ['auc', 'binary_logloss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBqC7e6yn4wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_list_lgbm = []\n",
        "def HPO_lgbm(lgb_hps):\n",
        "    num_round = 50\n",
        "    train_data=lgb.Dataset(X_train,label=y_train)\n",
        "    lgbm=lgb.train(lgb_hps,train_data,num_round)\n",
        "    ypred2=lgbm.predict(X_test)\n",
        "    accuracy_lgbm = multiclass_roc_auc_score(y_test,ypred2).mean()\n",
        "    accuracy_list_lgbm.append(accuracy_lgbm)\n",
        "    return {'loss': -accuracy_lgbm, 'status': STATUS_OK }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6osQaeMn4zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trials = Trials()\n",
        "best_lgbm = fmin(fn= HPO_lgbm,\n",
        "            space= lgb_hps,\n",
        "            algo= tpe.suggest,\n",
        "            max_evals = 80,\n",
        "            trials = trials\n",
        "            )\n",
        "max_acc_lgbm = max(accuracy_list_lgbm)\n",
        "print(\"Best Hyperparameters for LGBM are: \\n\")\n",
        "best_lgbm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATJzh086n2pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = ['num_leaves','max_depth','n_estimators','feature_fraction','bagging_fraction','learning_rate','lambda_l1','lambda_l2']\n",
        "f, axes = plt.subplots(nrows=4, ncols=2, figsize=(10,8))\n",
        "f.tight_layout()\n",
        "cmap = plt.cm.jet\n",
        "for i, val in enumerate(parameters):\n",
        "    print(\"Best \" + str(val) + \"   =   \" + str(best_lgbm[val]))\n",
        "    xs = np.array([t['misc']['vals'][val] for t in trials.trials]).ravel()\n",
        "    ys = [-t['result']['loss'] for t in trials.trials]\n",
        "    xs, ys = zip(*sorted(zip(xs, ys)))\n",
        "    ys = np.array(ys)\n",
        "    c=np.array(cmap(float(i)/len(parameters)))\n",
        "    axes[i//2,i%2].scatter(xs, ys, s=20, linewidth=0.01, alpha=0.5, c=c.reshape(1,-1))\n",
        "    axes[i//2,i%2].scatter(best_lgbm[val],max_acc_lgbm,color = \"red\")\n",
        "    axes[i//2,i%2].set_title(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpNPeWWQoFEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFiGeOJo1y2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = { \n",
        "            'num_leaves': num_leaves_list[best_lgbm['num_leaves']],\n",
        "            'max_depth': best_lgbm['max_depth'],\n",
        "            'n_estimators': best_lgbm['n_estimators'],\n",
        "            'feature_fraction':best_lgbm['feature_fraction'],\n",
        "            'bagging_fraction':best_lgbm['bagging_fraction'],\n",
        "            'learning_rate':best_lgbm['learning_rate'],\n",
        "            'lambda_l1': best_lgbm['lambda_l1'],\n",
        "            'lambda_l2':best_lgbm['lambda_l2']\n",
        "          }\n",
        "train_data=lgb.Dataset(X_train,label=y_train)\n",
        "\n",
        "num_round=100\n",
        "t1=datetime.now()\n",
        "lgbm=lgb.train(params,train_data,num_round)\n",
        "t2=datetime.now()\n",
        "execution_time_lgbm = t2-t1\n",
        "t3 = datetime.now()\n",
        "ypred2=lgbm.predict(X_test)\n",
        "t4 = datetime.now()\n",
        "\n",
        "for i in range(0,len(ypred2)): \n",
        "    if ypred2[i] >=0.5:\n",
        "        ypred2[i] = 1\n",
        "    else:\n",
        "        ypred2[i] = 0\n",
        "accuracy_lgbm = round(accuracy_score(ypred2,y_test),5)\n",
        "print(\"Accuracy score = \",accuracy_lgbm*100,\"%\")\n",
        "print(\"Execution time = \",execution_time_lgbm)\n",
        "print(\"Prediction time = \",t4-t3)\n",
        "lgbm_train_time = t2-t1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI5vC_wXqW9E",
        "colab_type": "text"
      },
      "source": [
        "# **Fit XGBoost model to the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS5EUWCAphJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb_hps = {  \n",
        "            'learning_rate':     hp.loguniform('learning_rate', -5.0, -2.3),\n",
        "            'max_depth':         hp.choice('max_depth',np.arange(5,16,1,dtype = int)),\n",
        "            'lambda':            hp.quniform('lambda',2, 16, 1),\n",
        "            'subsample':        hp.quniform('subsample',0.1,1.0,0.1),\n",
        "            'colsample_bytree': hp.quniform('colsample_bytree',0.3, 0.8, 0.1),\n",
        "            'min_split_loss' : hp.quniform('min_split_loss',0.1,2.0,0.1)\n",
        "        }\n",
        "\n",
        "depth_list = [i for i in range(5,16,1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFC1NTFxphMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_list_xgb = []\n",
        "def HPO_xgb(xgb_hps):\n",
        "    model = model = XGBClassifier(**xgb_hps)\n",
        "    model.fit(X_train,y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy_xgb = accuracy_score(y_pred,y_test).mean()\n",
        "    accuracy_list_xgb.append(accuracy_xgb)\n",
        "    return {'loss': -accuracy_xgb, 'status': STATUS_OK }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl21ZCnprLZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trials = Trials()\n",
        "best_xgb = fmin(fn= HPO_xgb,\n",
        "            space= xgb_hps,\n",
        "            algo= tpe.suggest,\n",
        "            max_evals = 1,\n",
        "            trials = trials\n",
        "            )\n",
        "max_acc_xgb = max(accuracy_list_xgb)\n",
        "print(\"Best Hyperparameters for XGBoost are: \\n\")\n",
        "best_xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zEgnZvurO-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = ['max_depth','subsample','learning_rate','min_split_loss','lambda','colsample_bytree']\n",
        "f, axes = plt.subplots(nrows=3, ncols=2, figsize=(15,8))\n",
        "f.tight_layout()\n",
        "cmap = plt.cm.jet\n",
        "for i, val in enumerate(parameters):\n",
        "    if val == 'max_depth':\n",
        "      best_xgb[val] = depth_list[best_xgb[val]]\n",
        "    print(\"Best \" + str(val) + \"   =   \" + str(best_xgb[val]))\n",
        "    xs = np.array([t['misc']['vals'][val] for t in trials.trials]).ravel()\n",
        "    ys = [-t['result']['loss'] for t in trials.trials]\n",
        "    xs, ys = zip(*sorted(zip(xs, ys)))\n",
        "    ys = np.array(ys)\n",
        "    c=np.array(cmap(float(i)/len(parameters)))\n",
        "    axes[i//2,i%2].scatter(xs, ys, s=20, linewidth=0.01, alpha=0.5, c=c.reshape(1,-1))\n",
        "    axes[i//2,i%2].scatter(best_xgb[val],max_acc_xgb,color = \"red\")\n",
        "    axes[i//2,i%2].set_title(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-TG1-CH2CIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(**best_xgb)\n",
        "t1=datetime.now()\n",
        "model.fit(X_train,y_train)\n",
        "t2=datetime.now()\n",
        "execution_time_xgb = t2-t1\n",
        "t3 = datetime.now()\n",
        "y_pred = model.predict(X_test)\n",
        "t4 = datetime.now()\n",
        "predictions = [round(value) for value in y_pred]\n",
        "accuracy_xgb = round(accuracy_score(y_pred,y_test),5)\n",
        "print(\"Accuracy score = \",accuracy_xgb*100,\"%\")\n",
        "print(\"Execution time = \",execution_time_xgb)\n",
        "print(\"Prediction time = \",t4-t3)\n",
        "xgb_train_time = t2-t1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l_hOR5MqejH",
        "colab_type": "text"
      },
      "source": [
        "# **Results and Plots**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyoBxLc7qggn",
        "colab_type": "text"
      },
      "source": [
        "# **1.Accuracy Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhH9vbUf5QFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (4,5))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "algorithms = ['LightGBM','XGBoost','CatBoost']\n",
        "accuracy = [accuracy_lgbm*100, accuracy_xgb*100,accuracy_cat_boost*100]\n",
        "g = ax.bar(algorithms,accuracy)\n",
        "plt.title(\"Accuracy Plot\")\n",
        "plt.xlabel(\"Algorithms on the Numeric Dataset\")\n",
        "plt.ylabel(\"Accuracy in %\")\n",
        "bar_label = [accuracy_lgbm*100, accuracy_xgb*100,accuracy_cat_boost*100]\n",
        "def autolabel(rects):\n",
        "    for idx,rect in enumerate(g):\n",
        "        height = rect.get_height()\n",
        "        ax.text(rect.get_x() + rect.get_width()/2., 1.0*height,\n",
        "                bar_label[idx],\n",
        "                ha='center', va='bottom', rotation=0)\n",
        "\n",
        "autolabel(g)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au0tDuRqqozN",
        "colab_type": "text"
      },
      "source": [
        "# **2.Training Time Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROMFEo61hzLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lg = float(str(lgbm_train_time)[5:])\n",
        "cb = float(str(cat_boost_train_time)[5:])\n",
        "xgb = float(str(xgb_train_time)[5:])\n",
        "fig1 = plt.figure(figsize = (4,5))\n",
        "ay = fig1.add_axes([0,0,1,1])\n",
        "algorithms = ['LightGBM','XGBoost','CatBoost']\n",
        "training_time = [lg,xgb,cb]\n",
        "g1 = ay.bar(algorithms,training_time)\n",
        "plt.title(\"Training Time Plot\")\n",
        "plt.xlabel(\"Algorithms on the Numeric Dataset\")\n",
        "plt.ylabel(\"Time Taken in Seconds\")\n",
        "bar_label = training_time\n",
        "def autolabel1(rects):\n",
        "    for idx,rect in enumerate(g1):\n",
        "        height = rect.get_height()\n",
        "        ay.text(rect.get_x() + rect.get_width()/2., 1.0*height,\n",
        "                bar_label[idx],\n",
        "                ha='center', va='bottom', rotation=0)\n",
        "\n",
        "autolabel1(g1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx343xBx4xnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}